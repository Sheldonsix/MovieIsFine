#!/usr/bin/env python3
"""
æ‰¹é‡çˆ¬å–æ‰€æœ‰ç”µå½±çš„ IMDB å®¶é•¿æŒ‡å—ä¿¡æ¯

Usage:
    python batch_scrape_parental_guide.py
    python batch_scrape_parental_guide.py --delay 5
    python batch_scrape_parental_guide.py --start-index 50
"""

import json
import os
import random
import re
import time
from pathlib import Path

from imdb_parental_guide_scraper import IMDBParentalGuideScraper, save_to_json


def extract_imdb_ids_from_movies_ts(file_path: str) -> list[str]:
    """ä» movies.ts æå–æ‰€æœ‰ imdbId"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # åŒ¹é…æ‰€æœ‰ imdbId
    pattern = r'"imdbId":\s*"(tt\d+)"'
    return re.findall(pattern, content)


def batch_scrape(
    imdb_ids: list[str],
    output_dir: str,
    delay: float = 3.0,
    start_index: int = 0,
    checkpoint_file: str = "checkpoint.json"
):
    """
    æ‰¹é‡çˆ¬å–å®¶é•¿æŒ‡å—

    Args:
        imdb_ids: IMDb ID åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        delay: è¯·æ±‚é—´éš”ï¼ˆé¿å…è¢«å°ï¼‰
        start_index: èµ·å§‹ç´¢å¼•ï¼ˆç”¨äºæ–­ç‚¹ç»­çˆ¬ï¼‰
        checkpoint_file: æ£€æŸ¥ç‚¹æ–‡ä»¶
    """
    os.makedirs(output_dir, exist_ok=True)
    scraper = IMDBParentalGuideScraper(timeout=30, max_retries=3)

    results = []
    failed = []

    # åŠ è½½å·²æœ‰çš„æ£€æŸ¥ç‚¹
    checkpoint_path = os.path.join(output_dir, checkpoint_file)
    if os.path.exists(checkpoint_path) and start_index == 0:
        with open(checkpoint_path, 'r', encoding='utf-8') as f:
            checkpoint = json.load(f)
            start_index = checkpoint.get('last_index', 0) + 1
            results = checkpoint.get('results', [])
            failed = checkpoint.get('failed', [])
            print(f"ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼Œèµ·å§‹ç´¢å¼•: {start_index}")

    total = len(imdb_ids)

    for i, imdb_id in enumerate(imdb_ids[start_index:], start=start_index):
        print(f"\n[{i + 1}/{total}] æ­£åœ¨çˆ¬å–: {imdb_id}")

        try:
            guide = scraper.scrape(imdb_id)

            if guide:
                # ä¿å­˜å•ä¸ªæ–‡ä»¶
                output_path = os.path.join(output_dir, f"{imdb_id}_parental_guide.json")
                save_to_json(guide, output_path)
                results.append({
                    "imdb_id": imdb_id,
                    "status": "success",
                    "title": guide.title
                })
                print(f"âœ“ æˆåŠŸ: {guide.title}")
            else:
                failed.append({"imdb_id": imdb_id, "error": "scrape returned None"})
                print(f"âœ— å¤±è´¥: {imdb_id}")

        except Exception as e:
            failed.append({"imdb_id": imdb_id, "error": str(e)})
            print(f"âœ— å¼‚å¸¸: {imdb_id} - {e}")

        # ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆæ¯10ä¸ªä¿å­˜ä¸€æ¬¡ï¼‰
        if (i + 1) % 10 == 0:
            with open(checkpoint_path, 'w', encoding='utf-8') as f:
                json.dump({
                    "last_index": i,
                    "results": results,
                    "failed": failed
                }, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜ ({i + 1}/{total})")

        # éšæœºåŒ–è¯·æ±‚é—´éš”ï¼Œé¿å…è¢«æ£€æµ‹
        if i < total - 1:
            actual_delay = delay + random.uniform(0, 2)
            time.sleep(actual_delay)

    # ä¿å­˜æœ€ç»ˆç»“æœæ±‡æ€»
    summary_path = os.path.join(output_dir, "scrape_summary.json")
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump({
            "total": total,
            "success": len(results),
            "failed_count": len(failed),
            "failed": failed
        }, f, ensure_ascii=False, indent=2)

    # æ¸…ç†æ£€æŸ¥ç‚¹æ–‡ä»¶
    if os.path.exists(checkpoint_path):
        os.remove(checkpoint_path)

    print(f"\n{'=' * 50}")
    print(f"çˆ¬å–å®Œæˆï¼æˆåŠŸ: {len(results)}, å¤±è´¥: {len(failed)}")
    print(f"ç»“æœä¿å­˜åœ¨: {output_dir}")


def main():
    import argparse

    parser = argparse.ArgumentParser(description="æ‰¹é‡çˆ¬å– IMDB å®¶é•¿æŒ‡å—")
    parser.add_argument(
        "--movies-file",
        default="../src/data/movies.ts",
        help="movies.ts æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ../src/data/movies.ts)"
    )
    parser.add_argument(
        "--output-dir",
        default="./parental_guides",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: ./parental_guides)"
    )
    parser.add_argument(
        "--delay",
        type=float,
        default=3.0,
        help="è¯·æ±‚é—´éš”ç§’æ•°ï¼Œå»ºè®® 3-5 ç§’ (é»˜è®¤: 3.0)"
    )
    parser.add_argument(
        "--start-index",
        type=int,
        default=0,
        help="èµ·å§‹ç´¢å¼•ï¼Œç”¨äºæ‰‹åŠ¨æ–­ç‚¹ç»­çˆ¬ (é»˜è®¤: 0)"
    )
    args = parser.parse_args()

    # è·å–è„šæœ¬ç›®å½•
    script_dir = Path(__file__).parent.absolute()
    movies_path = script_dir / args.movies_file
    output_dir = script_dir / args.output_dir

    # æ£€æŸ¥ movies.ts æ˜¯å¦å­˜åœ¨
    if not movies_path.exists():
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {movies_path}")
        exit(1)

    # æå– IMDb IDs
    imdb_ids = extract_imdb_ids_from_movies_ts(str(movies_path))
    print(f"æ‰¾åˆ° {len(imdb_ids)} éƒ¨ç”µå½±")

    if not imdb_ids:
        print("é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½• imdbId")
        exit(1)

    # æ˜¾ç¤ºé¢„ä¼°æ—¶é—´
    estimated_time = len(imdb_ids) * (args.delay + 1)  # åŠ ä¸Šéšæœºå»¶è¿Ÿå’Œå¤„ç†æ—¶é—´
    print(f"é¢„ä¼°è€—æ—¶: {estimated_time / 60:.1f} åˆ†é’Ÿ")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print("-" * 50)

    # å¼€å§‹æ‰¹é‡çˆ¬å–
    batch_scrape(
        imdb_ids=imdb_ids,
        output_dir=str(output_dir),
        delay=args.delay,
        start_index=args.start_index
    )


if __name__ == "__main__":
    main()
